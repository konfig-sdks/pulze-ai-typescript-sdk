/*
Pulze.ai API

At Pulze it's our mission to supercharge today's workforce with AI to maximize the world's prosperity. We are doing so by enabling companies of any size to securely leverage Large Language Models (LLM) and easily build AI features into their apps. Our enterprise platform has access to all best in class LLMs and can route user requests to the most relevant model to get the highest quality response at the best price thanks to our smart meta model. End users can leverage pre-built applications, such as our Marketing AI product, or build custom apps on top of the Pulze Platform.

We are a VC Funded, early stage startup based in San Francisco.

The version of the OpenAPI document: 0.1.0


NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/
import type * as buffer from "buffer"

import { ModelParts } from './model-parts';
import { PulzeEngineTokens } from './pulze-engine-tokens';
import { RankedScoringModels } from './ranked-scoring-models';
import { TemperatureProperty } from './temperature-property';

/**
 * 
 * @export
 * @interface PulzeEngineResponseMetadata
 */
export interface PulzeEngineResponseMetadata {
    /**
     * The ID of the app this request belongs to
     * @type {string}
     * @memberof PulzeEngineResponseMetadata
     */
    'app_id'?: string;
    /**
     * Category assigned to this request (Science, Health, Games...)
     * @type {string}
     * @memberof PulzeEngineResponseMetadata
     */
    'category'?: string;
    /**
     * Price difference -- compared with GPT-4
     * @type {PulzeEngineTokens}
     * @memberof PulzeEngineResponseMetadata
     */
    'cost_savings'?: PulzeEngineTokens;
    /**
     * Cost (in $) of the request
     * @type {PulzeEngineTokens}
     * @memberof PulzeEngineResponseMetadata
     */
    'costs'?: PulzeEngineTokens;
    /**
     * If an error occurs, it will be stored here
     * @type {string}
     * @memberof PulzeEngineResponseMetadata
     */
    'error'?: string;
    /**
     * Extra data
     * @type {object}
     * @memberof PulzeEngineResponseMetadata
     */
    'extra'?: object;
    /**
     * Custom labels (metadata) sent along in the request
     * @type {{ [key: string]: string; }}
     * @memberof PulzeEngineResponseMetadata
     */
    'labels'?: { [key: string]: string; };
    /**
     * The time it took for the Provider to return a response
     * @type {number}
     * @memberof PulzeEngineResponseMetadata
     */
    'latency'?: number;
    /**
     * Maximum number of tokens that can be used in the request+response.Leave empty to make it automatic, and set to `-1` to use the maximum context size (model-dependent)
     * @type {number}
     * @memberof PulzeEngineResponseMetadata
     */
    'max_tokens'?: number;
    /**
     * The model used in the request
     * @type {ModelParts}
     * @memberof PulzeEngineResponseMetadata
     */
    'model'?: ModelParts;
    /**
     * The number of retries needed to get the answer. `null` or `0` means no retries were required
     * @type {number}
     * @memberof PulzeEngineResponseMetadata
     */
    'retries'?: number;
    /**
     * The score for the currently used LLM
     * @type {number}
     * @memberof PulzeEngineResponseMetadata
     */
    'score'?: number;
    /**
     * A ranking of the best models for a given request
     * @type {RankedScoringModels}
     * @memberof PulzeEngineResponseMetadata
     */
    'scores'?: RankedScoringModels;
    /**
     * Status code of the response
     * @type {number}
     * @memberof PulzeEngineResponseMetadata
     */
    'status_code'?: number;
    /**
     * 
     * @type {TemperatureProperty}
     * @memberof PulzeEngineResponseMetadata
     */
    'temperature'?: TemperatureProperty;
}

