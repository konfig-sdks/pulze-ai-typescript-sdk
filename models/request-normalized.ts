/*
Pulze.ai API

At Pulze it's our mission to supercharge today's workforce with AI to maximize the world's prosperity. We are doing so by enabling companies of any size to securely leverage Large Language Models (LLM) and easily build AI features into their apps. Our enterprise platform has access to all best in class LLMs and can route user requests to the most relevant model to get the highest quality response at the best price thanks to our smart meta model. End users can leverage pre-built applications, such as our Marketing AI product, or build custom apps on top of the Pulze Platform.

We are a VC Funded, early stage startup based in San Francisco.

The version of the OpenAPI document: 0.1.0


NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/
import type * as buffer from "buffer"

import { PulzeCompletionRequest } from './pulze-completion-request';
import { PulzeEngineResponse } from './pulze-engine-response';
import { RequestInDBBase } from './request-in-dbbase';

/**
 * 
 * @export
 * @interface RequestNormalized
 */
export interface RequestNormalized {
    /**
     * The ID of the app that performed the request
     * @type {string}
     * @memberof RequestNormalized
     */
    'app_id'?: string;
    /**
     * Extra model settings inferred from namespace
     * @type {string}
     * @memberof RequestNormalized
     */
    'at'?: string;
    /**
     * The children of the Request. Will equal None unless you use eager loading in the query
     * @type {Array<RequestInDBBase>}
     * @memberof RequestNormalized
     */
    'children'?: Array<RequestInDBBase>;
    /**
     * Number of tokens the response used
     * @type {number}
     * @memberof RequestNormalized
     */
    'completion_tokens': number;
    /**
     * Cost (in $) of the response
     * @type {number}
     * @memberof RequestNormalized
     */
    'completion_tokens_cost': number;
    /**
     * Cost (in $) saved in the completion costs comparison to the benchmark model
     * @type {number}
     * @memberof RequestNormalized
     */
    'completion_tokens_cost_savings': number;
    /**
     * When a request requires multiple intermediate calls, they are stored as \'no costs incurred\' -- that way we can store the costs, but don\'t charge the user
     * @type {boolean}
     * @memberof RequestNormalized
     */
    'costs_incurred'?: boolean;
    /**
     * When the request was performed
     * @type {string}
     * @memberof RequestNormalized
     */
    'created'?: string;
    /**
     * A free text providing more detailed feedback
     * @type {string}
     * @memberof RequestNormalized
     */
    'feedback'?: string;
    /**
     * The rating for the request
     * @type {boolean}
     * @memberof RequestNormalized
     */
    'good_answer'?: boolean;
    /**
     * ID of the request
     * @type {string}
     * @memberof RequestNormalized
     */
    'id': string;
    /**
     * Time it took for the LLM to respond
     * @type {number}
     * @memberof RequestNormalized
     */
    'latency'?: number;
    /**
     * The name of the model. Can belong to many providers
     * @type {string}
     * @memberof RequestNormalized
     */
    'model': string;
    /**
     * The ID of the model used
     * @type {string}
     * @memberof RequestNormalized
     */
    'model_id': string;
    /**
     * The name of the provider\'s model which was used to answer the request
     * @type {string}
     * @memberof RequestNormalized
     */
    'namespace'?: string;
    /**
     * The owner of the model. Sometimes, for a provider/model combination, many instances exist, trained on different data
     * @type {string}
     * @memberof RequestNormalized
     */
    'owner'?: string;
    /**
     * The parent of the Request, if any. Requests which are part of a series of sub-requests (like multiple LLM calls, or RAG) will have the final, resulting Log as parent.
     * @type {RequestInDBBase}
     * @memberof RequestNormalized
     */
    'parent'?: RequestInDBBase;
    /**
     * Reference to the ID of the parent of this log. A log has a parent when it\'s a subrequest used to retrieve the final answer.
     * @type {string}
     * @memberof RequestNormalized
     */
    'parent_id'?: string;
    /**
     * The payload sent with the request
     * @type {PulzeCompletionRequest}
     * @memberof RequestNormalized
     */
    'payload'?: PulzeCompletionRequest;
    /**
     * How much is logged? 1: everything, 2: mask request+response (but show log), 3: Not visible, not retrievable, no information stored.
     * @type {number}
     * @memberof RequestNormalized
     */
    'privacy_level'?: RequestNormalizedPrivacyLevelEnum;
    /**
     * The prompt in text format
     * @type {string}
     * @memberof RequestNormalized
     */
    'prompt'?: string;
    /**
     * Number of tokens the request used
     * @type {number}
     * @memberof RequestNormalized
     */
    'prompt_tokens': number;
    /**
     * Cost (in $) of the prompt
     * @type {number}
     * @memberof RequestNormalized
     */
    'prompt_tokens_cost': number;
    /**
     * Cost (in $) saved in the prompt costs comparison to the benchmark model
     * @type {number}
     * @memberof RequestNormalized
     */
    'prompt_tokens_cost_savings': number;
    /**
     * The provider for the model.
     * @type {string}
     * @memberof RequestNormalized
     */
    'provider'?: string;
    /**
     * The type of request (text completion or chat) the user sends and expects back
     * @type {string}
     * @memberof RequestNormalized
     */
    'request_type'?: RequestNormalizedRequestTypeEnum;
    /**
     * The response object
     * @type {PulzeEngineResponse}
     * @memberof RequestNormalized
     */
    'response': PulzeEngineResponse;
    /**
     * The response in text format
     * @type {string}
     * @memberof RequestNormalized
     */
    'response_text'?: string;
    /**
     * The status code of the request to the AI model
     * @type {number}
     * @memberof RequestNormalized
     */
    'status_code'?: number;
    /**
     * The timestamp of the request, in milliseconds
     * @type {number}
     * @memberof RequestNormalized
     */
    'timestamp': number;
    /**
     * Number of tokens of (request + response)
     * @type {number}
     * @memberof RequestNormalized
     */
    'total_tokens': number;
    /**
     * Cost (in $) of the (request + response)
     * @type {number}
     * @memberof RequestNormalized
     */
    'total_tokens_cost': number;
    /**
     * Cost (in $) saved in total, in comparison to the benchmark model
     * @type {number}
     * @memberof RequestNormalized
     */
    'total_tokens_cost_savings': number;
}

type RequestNormalizedPrivacyLevelEnum = 1 | 2 | 3
type RequestNormalizedRequestTypeEnum = 'completions' | 'chat_completions'


