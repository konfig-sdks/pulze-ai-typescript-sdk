/*
Pulze.ai API

At Pulze it's our mission to supercharge today's workforce with AI to maximize the world's prosperity. We are doing so by enabling companies of any size to securely leverage Large Language Models (LLM) and easily build AI features into their apps. Our enterprise platform has access to all best in class LLMs and can route user requests to the most relevant model to get the highest quality response at the best price thanks to our smart meta model. End users can leverage pre-built applications, such as our Marketing AI product, or build custom apps on top of the Pulze Platform.

We are a VC Funded, early stage startup based in San Francisco.

The version of the OpenAPI document: 0.1.0


NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/
import type * as buffer from "buffer"

import { PulzeCompletionRequest } from './pulze-completion-request';
import { PulzeEngineResponse } from './pulze-engine-response';

/**
 * 
 * @export
 * @interface RequestInDBBase
 */
export interface RequestInDBBase {
    /**
     * The ID of the app that performed the request
     * @type {string}
     * @memberof RequestInDBBase
     */
    'app_id'?: string;
    /**
     * The children of the Request. Will equal None unless you use eager loading in the query
     * @type {Array<any>}
     * @memberof RequestInDBBase
     */
    'children'?: Array<any>;
    /**
     * When a request requires multiple intermediate calls, they are stored as \'no costs incurred\' -- that way we can store the costs, but don\'t charge the user
     * @type {boolean}
     * @memberof RequestInDBBase
     */
    'costs_incurred'?: boolean;
    /**
     * A free text providing more detailed feedback
     * @type {string}
     * @memberof RequestInDBBase
     */
    'feedback'?: string;
    /**
     * The rating for the request
     * @type {boolean}
     * @memberof RequestInDBBase
     */
    'good_answer'?: boolean;
    /**
     * ID of the request
     * @type {string}
     * @memberof RequestInDBBase
     */
    'id': string;
    /**
     * The name of the provider\'s model which was used to answer the request
     * @type {string}
     * @memberof RequestInDBBase
     */
    'namespace'?: string;
    /**
     * The parent of the Request, if any. Requests which are part of a series of sub-requests (like multiple LLM calls, or RAG) will have the final, resulting Log as parent.
     * @type {any}
     * @memberof RequestInDBBase
     */
    'parent'?: any;
    /**
     * Reference to the ID of the parent of this log. A log has a parent when it\'s a subrequest used to retrieve the final answer.
     * @type {string}
     * @memberof RequestInDBBase
     */
    'parent_id'?: string;
    /**
     * The payload sent with the request
     * @type {PulzeCompletionRequest}
     * @memberof RequestInDBBase
     */
    'payload'?: PulzeCompletionRequest;
    /**
     * How much is logged? 1: everything, 2: mask request+response (but show log), 3: Not visible, not retrievable, no information stored.
     * @type {number}
     * @memberof RequestInDBBase
     */
    'privacy_level'?: RequestInDBBasePrivacyLevelEnum;
    /**
     * The prompt in text format
     * @type {string}
     * @memberof RequestInDBBase
     */
    'prompt'?: string;
    /**
     * The type of request (text completion or chat) the user sends and expects back
     * @type {string}
     * @memberof RequestInDBBase
     */
    'request_type'?: RequestInDBBaseRequestTypeEnum;
    /**
     * The response object
     * @type {PulzeEngineResponse}
     * @memberof RequestInDBBase
     */
    'response': PulzeEngineResponse;
    /**
     * The response in text format
     * @type {string}
     * @memberof RequestInDBBase
     */
    'response_text'?: string;
    /**
     * The status code of the request to the AI model
     * @type {number}
     * @memberof RequestInDBBase
     */
    'status_code'?: number;
}

type RequestInDBBasePrivacyLevelEnum = 1 | 2 | 3
type RequestInDBBaseRequestTypeEnum = 'completions' | 'chat_completions'


